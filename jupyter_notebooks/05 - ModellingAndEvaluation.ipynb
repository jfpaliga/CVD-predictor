{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# **Classification Model and Evaluation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "* Answer business requirement 2:\n",
        "    * The client is interested in using patient data to predict whether or not a patient is at risk of heart disease.\n",
        "* Fit and evaluate a classification model to predict if a patient has heart disease or not.\n",
        "\n",
        "## Inputs\n",
        "\n",
        "* outputs/datasets/collection/HeartDiseasePrediction.csv\n",
        "* Instructions on data cleaning and feature engineering from the relevant notebooks\n",
        "\n",
        "## Outputs\n",
        "\n",
        "* Data cleaning, feature engineering and modelling pipelines\n",
        "* Feature importance plot\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqP-UeN-z3i2"
      },
      "source": [
        "# Change working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* We are assuming you will store the notebooks in a subfolder, therefore when running the notebook in the editor, you will need to change the working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOGIGS-uz3i2"
      },
      "source": [
        "We need to change the working directory from its current folder to its parent folder\n",
        "* We access the current directory with os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZfF_j-Bz3i4",
        "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "\n",
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MWW8E7lz3i7"
      },
      "source": [
        "We want to make the parent of the current directory the new current directory\n",
        "* os.path.dirname() gets the parent directory\n",
        "* os.chir() defines the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TwHsQRWjz3i9",
        "outputId": "86849db3-cd2f-4cc5-ebb8-2d0caafa1a2c"
      },
      "outputs": [],
      "source": [
        "os.chdir(os.path.dirname(current_dir))\n",
        "print(\"You set a new current directory\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_xPk_Ijz3i-"
      },
      "source": [
        "Confirm the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vz3S-_kjz3jA",
        "outputId": "00b79ae4-75d0-4a96-d193-ac9ef9847ea2"
      },
      "outputs": [],
      "source": [
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mavJ8DibrcQ"
      },
      "source": [
        "# Load Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load the raw dataset and replace values of 0 in RestingBP and Cholesterol with NaN ready for the ML pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "df = pd.read_csv(\"outputs/datasets/collection/HeartDiseasePrediction.csv\")\n",
        "\n",
        "for col in [\"RestingBP\", \"Cholesterol\"]:\n",
        "    df[col] = df[col].replace(0, np.nan)\n",
        "\n",
        "df.isna().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY3l0-AxO93d"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFQo3ycuO-v6"
      },
      "source": [
        "# Classification ML Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Pipeline for Data Cleaning and Feature Engineering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "#Data Cleaning\n",
        "from feature_engine.imputation import MeanMedianImputer, RandomSampleImputer\n",
        "\n",
        "# Feature Engineering\n",
        "from feature_engine.discretisation import ArbitraryDiscretiser\n",
        "from feature_engine.encoding import OrdinalEncoder\n",
        "\n",
        "\n",
        "def DataCleaningandFeatEngPipeline():\n",
        "\n",
        "    pipeline = Pipeline([\n",
        "        (\"median_imputation\", MeanMedianImputer(imputation_method=\"median\",\n",
        "                                                variables=[\"RestingBP\"])),\n",
        "        (\"random_sample_imputation\", RandomSampleImputer(random_state=1,\n",
        "                                                         seed='general',\n",
        "                                                         variables=[\"Cholesterol\"])),\n",
        "        (\"arbitrary_discretisation\", ArbitraryDiscretiser(binning_dict={\"Oldpeak\":[-np.inf, 0, 1.5, np.inf]})),\n",
        "        (\"ordinal_encoding\", OrdinalEncoder(encoding_method=\"arbitrary\",\n",
        "                                            variables=[\"Sex\",\n",
        "                                                       \"ChestPainType\",\n",
        "                                                       \"FastingBS\",\n",
        "                                                       \"RestingECG\",\n",
        "                                                       \"ExerciseAngina\",\n",
        "                                                       \"ST_Slope\"])),\n",
        "        ])\n",
        "\n",
        "    return pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Pipeline for Modelling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Feature Scaling\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Feature Selection\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "\n",
        "# ML Algorithms\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier, AdaBoostClassifier\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "\n",
        "def ClassificationPipeline(model):\n",
        "\n",
        "    pipeline = Pipeline([\n",
        "        (\"scaler\", StandardScaler()),\n",
        "        (\"feat_selection\", SelectFromModel(model)),\n",
        "        (\"model\", model),\n",
        "        ])\n",
        "\n",
        "    return pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Split Data into Train and Test Sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    df.drop([\"HeartDisease\"], axis=1),\n",
        "    df[\"HeartDisease\"],\n",
        "    test_size=0.2,\n",
        "    random_state=0,\n",
        ")\n",
        "\n",
        "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Check target distribution of train set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "sns.set_style(\"whitegrid\")\n",
        "y_train.value_counts().plot(kind='bar', title='Train Set Target Distribution')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* The target looks relatively balanced, however in order to try and minimise overfitting oversampling will be performed.\n",
        "* In order to do this, we first need to clean and encode the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_cleaning_feat_eng_pipeline = DataCleaningandFeatEngPipeline()\n",
        "X_train = data_cleaning_feat_eng_pipeline.fit_transform(X_train)\n",
        "X_test = data_cleaning_feat_eng_pipeline.transform(X_test)\n",
        "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "\n",
        "oversample = SMOTE(sampling_strategy='minority', random_state=0)\n",
        "X_train, y_train = oversample.fit_resample(X_train, y_train)\n",
        "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Check target distribution **after** oversampling."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_train.value_counts().plot(kind='bar', title='Train Set Target Distribution')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Hyperparameter Optimisation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Load custom hyperparameter optimisation class from CodeInstitute"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "\n",
        "class HyperparameterOptimizationSearch:\n",
        "\n",
        "    def __init__(self, models, params):\n",
        "        self.models = models\n",
        "        self.params = params\n",
        "        self.keys = models.keys()\n",
        "        self.grid_searches = {}\n",
        "\n",
        "    def fit(self, X, y, cv, n_jobs, verbose=1, scoring=None, refit=False):\n",
        "        for key in self.keys:\n",
        "            print(f\"\\nRunning GridSearchCV for {key} \\n\")\n",
        "\n",
        "            model = ClassificationPipeline(self.models[key])\n",
        "            params = self.params[key]\n",
        "            gs = GridSearchCV(model, params, cv=cv, n_jobs=n_jobs,\n",
        "                              verbose=verbose, scoring=scoring, )\n",
        "            gs.fit(X, y)\n",
        "            self.grid_searches[key] = gs\n",
        "\n",
        "    def score_summary(self, sort_by='mean_score'):\n",
        "        def row(key, scores, params):\n",
        "            d = {\n",
        "                'estimator': key,\n",
        "                'min_score': min(scores),\n",
        "                'max_score': max(scores),\n",
        "                'mean_score': np.mean(scores),\n",
        "                'std_score': np.std(scores),\n",
        "            }\n",
        "            return pd.Series({**params, **d})\n",
        "\n",
        "        rows = []\n",
        "        for k in self.grid_searches:\n",
        "            params = self.grid_searches[k].cv_results_['params']\n",
        "            scores = []\n",
        "            for i in range(self.grid_searches[k].cv):\n",
        "                key = \"split{}_test_score\".format(i)\n",
        "                r = self.grid_searches[k].cv_results_[key]\n",
        "                scores.append(r.reshape(len(params), 1))\n",
        "\n",
        "            all_scores = np.hstack(scores)\n",
        "            for p, s in zip(params, all_scores):\n",
        "                rows.append((row(k, s, p)))\n",
        "\n",
        "        df = pd.concat(rows, axis=1).T.sort_values([sort_by], ascending=False)\n",
        "        columns = ['estimator', 'min_score',\n",
        "                   'mean_score', 'max_score', 'std_score']\n",
        "        columns = columns + [c for c in df.columns if c not in columns]\n",
        "        return df[columns], self.grid_searches"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Finding the most suitable algorithm with HyperparameterOptimizationSearch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "models_quick_search = {\n",
        "    \"LogisticRegression\": LogisticRegression(random_state=0),\n",
        "    \"XGBClassifier\": XGBClassifier(random_state=0),\n",
        "    \"DecisionTreeClassifier\": DecisionTreeClassifier(random_state=0),\n",
        "    \"RandomForestClassifier\": RandomForestClassifier(random_state=0),\n",
        "    \"GradientBoostingClassifier\": GradientBoostingClassifier(random_state=0),\n",
        "    \"ExtraTreesClassifier\": ExtraTreesClassifier(random_state=0),\n",
        "    \"AdaBoostClassifier\": AdaBoostClassifier(random_state=0),\n",
        "}\n",
        "\n",
        "params_quick_search = {\n",
        "    \"LogisticRegression\": {},\n",
        "    \"XGBClassifier\": {},\n",
        "    \"DecisionTreeClassifier\": {},\n",
        "    \"RandomForestClassifier\": {},\n",
        "    \"GradientBoostingClassifier\": {},\n",
        "    \"ExtraTreesClassifier\": {},\n",
        "    \"AdaBoostClassifier\": {},\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Using **default** hyperparameters to find best algorithm, scored by recall (as per business requirement 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import make_scorer, recall_score\n",
        "\n",
        "\n",
        "search = HyperparameterOptimizationSearch(models=models_quick_search, params=params_quick_search)\n",
        "search.fit(X_train, y_train,\n",
        "           scoring =  make_scorer(recall_score, pos_label=1),\n",
        "           n_jobs=-1, cv=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Results of GridSearch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "grid_search_summary, grid_search_pipelines = search.score_summary(sort_by='mean_score')\n",
        "grid_search_summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The top three algorithms rated by mean score for recall were RandomForestClassifier, LogisticRegression and XGBClassifier.\n",
        "\n",
        "Using these three algorithms, extensive hyperparameter optimisation was carried out.\n",
        "\n",
        "For further details on how hyperparameter ranges were selected, please see the Hyperparameter Optimisation notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "models_search = {\n",
        "    \"RandomForestClassifier\": RandomForestClassifier(random_state=0),\n",
        "    \"LogisticRegression\": LogisticRegression(random_state=0),\n",
        "    \"XGBClassifier\":XGBClassifier(random_state=0),\n",
        "    \n",
        "}\n",
        "\n",
        "params_search = {\n",
        "    \"RandomForestClassifier\": {\n",
        "        \"model__n_estimators\": [50, 140, 300, 500],\n",
        "        \"model__max_depth\": [None, 4, 15],\n",
        "        \"model__min_samples_split\": [2, 5, 10, 15, 50],\n",
        "        \"model__min_samples_leaf\": [1, 2, 5, 10, 50],\n",
        "        \"model__max_leaf_nodes\": [None, 50],\n",
        "        \"model__max_features\": [None, \"sqrt\", \"log2\"],\n",
        "        },\n",
        "    \"LogisticRegression\":{\n",
        "        \"model__penalty\": [\"l2\", \"l1\", \"elasticnet\", None],\n",
        "        \"model__C\": [10, 2, 1.0, 0.5, 0.1],\n",
        "        \"model__tol\": [1e-3, 1e-4, 1e-5],\n",
        "        },\n",
        "    \"XGBClassifier\": {\n",
        "        \"model__n_estimators\": [10, 30, 50, 100, 200],\n",
        "        \"model__max_depth\": [None, 3, 15],\n",
        "        \"model__learning_rate\": [0.001, 0.01, 0.1],\n",
        "        \"model__gamma\": [0, 0.05, 0.075, 0.1],\n",
        "        \"model__min_child_weight\": [1, 3, 5, 7],\n",
        "        },\n",
        "        }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Using more extensive hyperparameter options"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "search = HyperparameterOptimizationSearch(models=models_search, params=params_search)\n",
        "search.fit(X_train, y_train,\n",
        "           scoring =  make_scorer(recall_score, pos_label=1),\n",
        "           n_jobs=-1, cv=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Results of GridSearch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "extensive_grid_search_summary, extensive_grid_search_pipelines = search.score_summary(sort_by='mean_score')\n",
        "extensive_grid_search_summary "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Save the best model and parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_model = extensive_grid_search_summary.iloc[0,0]\n",
        "best_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_parameters = extensive_grid_search_pipelines[best_model].best_params_\n",
        "best_parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define the pipeline using the findings from hyperparameter optimisation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "classification_pipeline = extensive_grid_search_pipelines[best_model].best_estimator_\n",
        "classification_pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Feature Importance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "With the optimal pipeline found, the importance of features to the model can be assessed using the ```.feature_importances_``` attribute.\n",
        "\n",
        "* We do this by assigning the features and their relative importance to a dataframe.\n",
        "* We then use this dataframe to plot a bar plot."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "classification_pipeline['feat_selection']\n",
        "\n",
        "df_feature_importance = (pd.DataFrame(data={\n",
        "    'Feature': X_train.columns[classification_pipeline['feat_selection'].get_support()],\n",
        "    'Importance': classification_pipeline['model'].feature_importances_})\n",
        "    .sort_values(by='Importance', ascending=False)\n",
        ")\n",
        "\n",
        "best_features = df_feature_importance[\"Feature\"].to_list()\n",
        "\n",
        "print(f\"* These are the {len(best_features)} most important features in descending order.\\n\"\n",
        "      f\"* The model was trained using these features: {best_features}\")\n",
        "\n",
        "df_feature_importance.plot(kind=\"bar\", x=\"Feature\", y=\"Importance\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "\n",
        "def confusion_matrix_and_report(X, y, pipeline, label_map):\n",
        "\n",
        "    prediction = pipeline.predict(X)\n",
        "\n",
        "    print('---  Confusion Matrix  ---')\n",
        "    print(pd.DataFrame(confusion_matrix(y_true=prediction, y_pred=y),\n",
        "          columns=[[\"Actual \" + sub for sub in label_map]],\n",
        "          index=[[\"Prediction \" + sub for sub in label_map]]\n",
        "          ))\n",
        "    print(\"\\n\")\n",
        "\n",
        "    print('---  Classification Report  ---')\n",
        "    print(classification_report(y, prediction, target_names=label_map), \"\\n\")\n",
        "\n",
        "\n",
        "def clf_performance(X_train, y_train, X_test, y_test, pipeline, label_map):\n",
        "    print(\"#### Train Set #### \\n\")\n",
        "    confusion_matrix_and_report(X_train, y_train, pipeline, label_map)\n",
        "\n",
        "    print(\"#### Test Set ####\\n\")\n",
        "    confusion_matrix_and_report(X_test, y_test, pipeline, label_map)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "clf_performance(X_train=X_train, y_train=y_train,\n",
        "                X_test=X_test, y_test=y_test,\n",
        "                pipeline=classification_pipeline,\n",
        "                label_map=[\"No Heart Disease\", \"Heart Disease\"]\n",
        "                )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Recall for heart disease was 89% on the train set and 88% on the test set and precision on no heart disease was 86% for the train set and 81% for the test set, passing the criteria set out in the ML business case."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Refitting the ML Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can refit the ML pipeline with the most important features to determine whether we get the same result as one fitted with all variables."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* The five most important features found from the model were \"ST_Slope\", \"ChestPainType\", \"MaxHR\", \"Age\" and \"Cholesterol\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Re-writing the ML Pipelines"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We had two pipelines due to a target balancing step: one for data cleaning and feature engineering, and another for modelling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def DataCleaningandFeatEngPipeline():\n",
        "    \n",
        "    pipeline = Pipeline([\n",
        "        (\"random_sample_imputation\", RandomSampleImputer(random_state=1,\n",
        "                                                         seed='general',\n",
        "                                                         variables=[\"Cholesterol\"])),\n",
        "        (\"ordinal_encoding\", OrdinalEncoder(encoding_method=\"arbitrary\",\n",
        "                                            variables=[\"ChestPainType\",\n",
        "                                                       \"ST_Slope\"])),\n",
        "        ])\n",
        "\n",
        "    return pipeline\n",
        "\n",
        "def ClassificationPipeline(model):\n",
        "\n",
        "    pipeline = Pipeline([\n",
        "        (\"scaler\", StandardScaler()),\n",
        "        (\"model\", model),\n",
        "        ])\n",
        "\n",
        "    return pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Split Train and Tests Sets Using Only Most Important Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    df.drop([\"HeartDisease\"], axis=1),\n",
        "    df[\"HeartDisease\"],\n",
        "    test_size=0.2,\n",
        "    random_state=0,\n",
        ")\n",
        "\n",
        "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Filter by most important features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train = X_train.filter(best_features)\n",
        "X_test = X_test.filter(best_features)\n",
        "\n",
        "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n",
        "X_train.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Handle Target Imbalance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First, we pass the data through the data cleaning and feature engineering pipeline and assess the target distribution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_cleaning_feat_eng_pipeline = DataCleaningandFeatEngPipeline()\n",
        "X_train = data_cleaning_feat_eng_pipeline.fit_transform(X_train)\n",
        "X_test = data_cleaning_feat_eng_pipeline.transform(X_test)\n",
        "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n",
        "\n",
        "y_train.value_counts().plot(kind='bar', title='Train Set Target Distribution')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then use SMOTE oversampling to rebalance the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "oversample = SMOTE(sampling_strategy='minority', random_state=0)\n",
        "X_train, y_train = oversample.fit_resample(X_train, y_train)\n",
        "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n",
        "\n",
        "y_train.value_counts().plot(kind='bar', title='Train Set Target Distribution')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Cross-Validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can then pass in the best model and hyperparameter values into the HyperparameterOptimisationSearch function to assess the new pipeline."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "models_search = {\n",
        "    \"RandomForestClassifier\": RandomForestClassifier(random_state=0),\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Hyperparameter values need to be stored in a list before being passed into the function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "params_search = {'RandomForestClassifier': {\n",
        "    'model__max_depth': [None],\n",
        "    'model__max_features': [None],\n",
        "    'model__max_leaf_nodes': [None],\n",
        "    'model__min_samples_leaf': [50],\n",
        "    'model__min_samples_split': [2],\n",
        "    'model__n_estimators': [50]\n",
        "    },\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "quick_search = HyperparameterOptimizationSearch(\n",
        "    models=models_search, params=params_search)\n",
        "quick_search.fit(X_train, y_train,\n",
        "                 scoring=make_scorer(recall_score, pos_label=1),\n",
        "                 n_jobs=-1, cv=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Checking the results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "grid_search_summary, grid_search_pipelines = quick_search.score_summary(sort_by='mean_score')\n",
        "grid_search_summary "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Defining the best classification pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_model = grid_search_summary.iloc[0, 0]\n",
        "classification_pipeline = grid_search_pipelines[best_model].best_estimator_\n",
        "classification_pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Evaluation of Pipeline on Train and Test Sets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As a reminder, the metrics defined in the ML business case were:\n",
        "* 75% recall on Heart Disease\n",
        "* 70% precision on No Heart Disease"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "clf_performance(X_train=X_train, y_train=y_train,\n",
        "                X_test=X_test, y_test=y_test,\n",
        "                pipeline=classification_pipeline,\n",
        "                label_map=[\"No Heart Disease\", \"Heart Disease\"]\n",
        "                )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Using the two most important features, the recall on heart disease was 89% for the train set and 88% for the test set. The precision on no heart disease was 87% for the train set and 81% for the test set.\n",
        "\n",
        "The metrics using these pipelines exceeds the criteria set out in the ML business case so we can use this pipeline moving forward."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltNetd085qHf"
      },
      "source": [
        "# Push files to Repo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The following files will be generated:\n",
        "\n",
        "* Train set\n",
        "* Test set\n",
        "* Data cleaning and feature engineering pipeline\n",
        "* Modeling pipeline\n",
        "* Feature Importance plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aKlnIozA4eQO",
        "outputId": "fd09bc1f-adb1-4511-f6ce-492a6af570c0"
      },
      "outputs": [],
      "source": [
        "import joblib\n",
        "\n",
        "\n",
        "version = \"v2\"\n",
        "file_path = f\"outputs/ml_pipeline/classification_model/{version}\"\n",
        "\n",
        "try:\n",
        "  os.makedirs(name=file_path)\n",
        "except Exception as e:\n",
        "  print(e)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Train Set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Save train set with variables already encoded (and after oversampling)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(X_train.shape)\n",
        "X_train.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train.to_csv(f\"{file_path}/X_train.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_train.to_csv(f\"{file_path}/y_train.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Test Set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Save test set with variables already encoded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(X_test.shape)\n",
        "X_test.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_test.to_csv(f\"{file_path}/X_test.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_test.to_csv(f\"{file_path}/y_test.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ML Pipelines"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Two pipelines will be saved: one for data cleaning and feature engineering, and another for modelling.\n",
        "\n",
        "* When predicting Live Data, both pipelines will be required\n",
        "* When predicting on the train and test sets, only the modelling pipeline is required as the data has already been processed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_cleaning_feat_eng_pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "joblib.dump(value=data_cleaning_feat_eng_pipeline,\n",
        "            filename=f\"{file_path}/data_cleaning_and_feat_engineering_pipeline.pkl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "classification_pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "joblib.dump(value=classification_pipeline,\n",
        "            filename=f\"{file_path}/classification_pipeline.pkl\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Feature Importance Plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_feature_importance.plot(kind=\"bar\", x=\"Feature\", y=\"Importance\")\n",
        "plt.savefig(f\"{file_path}/features_importance.png\", bbox_inches=\"tight\")\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "interpreter": {
      "hash": "8b8334dab9339717f727a1deaf837b322d7a41c20d15cc86be99a8e69ceec8ce"
    },
    "kernelspec": {
      "display_name": "Python 3.8.12 64-bit ('3.8.12': pyenv)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
